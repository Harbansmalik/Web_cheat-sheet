# GEN-AI ATTACKS

## 1Ô∏è‚É£ Prompt Injection
üß® Attack: Manipulate the prompt so the model does what the attacker wants (ignore instructions, leak data, etc.)
